from flask import Flask, request, jsonify, render_template
import os
import soundfile as sf
import subprocess
from speechbrain.inference import SpeakerRecognition

app = Flask(__name__)

UPLOAD_DIR = 'static/uploads'
os.makedirs(UPLOAD_DIR, exist_ok=True)

REGISTERED_WEBM = os.path.join(UPLOAD_DIR, 'registered.webm')
REGISTERED_WAV = os.path.join(UPLOAD_DIR, 'registered.wav')
VERIFY_WEBM = os.path.join(UPLOAD_DIR, 'verify.webm')
VERIFY_WAV = os.path.join(UPLOAD_DIR, 'verify.wav')
REGISTER_FLAG = os.path.join(UPLOAD_DIR, 'registered_flag.txt')

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ­ã‚°å‡ºåŠ›ï¼‰
try:
    print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    speaker_model = SpeakerRecognition.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb",
        savedir="pretrained_models/spkrec",
        run_opts={"symlink": False}
    )
    print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†ï¼")
except Exception as e:
    print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    speaker_model = None

# ç„¡éŸ³åˆ¤å®šé–¢æ•°
def is_silent(wav_path, threshold=0.04):
    data, samplerate = sf.read(wav_path)
    if len(data.shape) > 1:
        data = data.mean(axis=1)
    return max(abs(data)) < threshold

# WebMâ†’WAVå¤‰æ›é–¢æ•°ï¼ˆ2ç§’ã‚«ãƒƒãƒˆå¯¾å¿œï¼‰
def webm_to_wav(webm_path, wav_path):
    """
    WebMå½¢å¼ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ç§’ã§åˆ‡ã‚Šå‡ºã—WAVã¸å¤‰æ›
    """
    command = [
        "ffmpeg",
        "-y",
        "-i", webm_path,
        "-t", "2",           # â† éŒ²éŸ³é•·ã‚’2ç§’ã§ã‚«ãƒƒãƒˆ
        "-ar", "16000",      # â† 16kHzã«å¤‰æ›ï¼ˆãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰
        wav_path
    ]
    try:
        subprocess.run(command, check=True)
        print("âœ… ffmpegã§WAVå¤‰æ›ï¼†2ç§’åˆ‡ã‚Šå‡ºã—æˆåŠŸ")
    except subprocess.CalledProcessError as e:
        print(f"âŒ ffmpegå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        raise

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/register_voice', methods=['POST'])
def register_voice():
    audio = request.files['audio_data']
    audio.save(REGISTERED_WEBM)

    try:
        webm_to_wav(REGISTERED_WEBM, REGISTERED_WAV)
    except Exception as e:
        return jsonify({"result": "âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})

    if is_silent(REGISTERED_WAV):
        os.remove(REGISTERED_WEBM)
        os.remove(REGISTERED_WAV)
        if os.path.exists(REGISTER_FLAG):
            os.remove(REGISTER_FLAG)
        return jsonify({"result": "âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ã—ã£ã‹ã‚Šç™ºè©±ã—ã¦ãã ã•ã„ã€‚"})

    with open(REGISTER_FLAG, 'w') as f:
        f.write('registered')

    return jsonify({"result": "âœ… å£°ã®ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼"})

@app.route('/is_registered', methods=['GET'])
def is_registered():
    registered = os.path.exists(REGISTER_FLAG)
    return jsonify({"registered": registered})

@app.route('/reset_registration', methods=['POST'])
def reset_registration():
    for file_path in [REGISTERED_WEBM, REGISTERED_WAV, REGISTER_FLAG]:
        if os.path.exists(file_path):
            os.remove(file_path)
    return jsonify({"reset": True})

@app.route('/verify_voice', methods=['POST'])
def verify_voice():
    print("ğŸ” è©±è€…åˆ¤å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡")

    if not os.path.exists(REGISTER_FLAG):
        return jsonify({"result": "âš ï¸ å£°ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã¯ã€Œå£°ã‚’ç™»éŒ²ğŸ¤ã€ãƒœã‚¿ãƒ³ã§ç™»éŒ²ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"})

    audio = request.files['audio_data']
    audio.save(VERIFY_WEBM)
    print("âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡ãƒ»ä¿å­˜å®Œäº†")

    try:
        webm_to_wav(VERIFY_WEBM, VERIFY_WAV)
        print("âœ… WebM â†’ WAV å¤‰æ›æˆåŠŸ")
    except Exception as e:
        print(f"âŒ WebM â†’ WAV å¤‰æ›å¤±æ•—: {e}")
        return jsonify({"result": "âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})

    if is_silent(VERIFY_WAV):
        os.remove(VERIFY_WEBM)
        os.remove(VERIFY_WAV)
        return jsonify({"result": "âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ã—ã£ã‹ã‚Šç™ºè©±ã—ã¦ãã ã•ã„ã€‚"})

    if speaker_model is None:
        return jsonify({"result": "âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å†èµ·å‹•ãŒå¿…è¦ã§ã™ã€‚"})

    print("ğŸ§  ãƒ¢ãƒ‡ãƒ«ã§ã‚¹ã‚³ã‚¢åˆ¤å®šé–‹å§‹")
    score, _ = speaker_model.verify_files(REGISTERED_WAV, VERIFY_WAV)
    print(f"âœ… ã‚¹ã‚³ã‚¢è¨ˆç®—å®Œäº†: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ = {score.item():.4f}")

    os.remove(VERIFY_WEBM)
    os.remove(VERIFY_WAV)

    SCORE_THRESHOLD = 0.65
    if score.item() >= SCORE_THRESHOLD:
        result = f"âœ… æœ¬äººã®å£°ã§ã™ã€‚(é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score.item():.2f})"
    else:
        result = f"âŒ æœ¬äººã®å£°ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚(é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score.item():.2f})"

    print(f"ğŸ¤ åˆ¤å®šçµæœ: {result}")
    return jsonify({"result": result})

if __name__ == "__main__":
    app.run()