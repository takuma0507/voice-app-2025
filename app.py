from flask import Flask, request, jsonify, render_template
import os
import soundfile as sf
import subprocess
from speechbrain.inference import SpeakerRecognition

app = Flask(__name__)

UPLOAD_DIR = 'static/uploads'
os.makedirs(UPLOAD_DIR, exist_ok=True)

REGISTERED_WEBM = os.path.join(UPLOAD_DIR, 'registered.webm')
REGISTERED_WAV = os.path.join(UPLOAD_DIR, 'registered.wav')
VERIFY_WEBM = os.path.join(UPLOAD_DIR, 'verify.webm')
VERIFY_WAV = os.path.join(UPLOAD_DIR, 'verify.wav')
REGISTER_FLAG = os.path.join(UPLOAD_DIR, 'registered_flag.txt')

try:
    print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    speaker_model = SpeakerRecognition.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb",
        savedir="pretrained_models/spkrec",
        run_opts={"symlink": False}
    )
    print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†ï¼")
except Exception as e:
    print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    speaker_model = None

def is_silent(wav_path, threshold=0.04):
    data, samplerate = sf.read(wav_path)
    if len(data.shape) > 1:
        data = data.mean(axis=1)
    return max(abs(data)) < threshold

def webm_to_wav(webm_path, wav_path):
    command = ["ffmpeg", "-y", "-i", webm_path, "-t", "3", "-ar", "16000", wav_path]
    try:
        subprocess.run(command, check=True)
    except subprocess.CalledProcessError as e:
        print(f"âŒ ffmpegã‚¨ãƒ©ãƒ¼: {e}")
        raise

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/register_voice', methods=['POST'])
def register_voice():
    audio = request.files['audio_data']
    audio.save(REGISTERED_WEBM)

    try:
        webm_to_wav(REGISTERED_WEBM, REGISTERED_WAV)
        print("âœ… WebM â†’ WAV å¤‰æ›æˆåŠŸ")
    except Exception as e:
        print(f"âŒ WebM â†’ WAV å¤‰æ›å¤±æ•—: {e}")
        return jsonify({"result": "âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})

    if is_silent(REGISTERED_WAV):
        print("âš ï¸ ç™»éŒ²éŸ³å£°ãŒç„¡éŸ³ã¨åˆ¤å®š")
        os.remove(REGISTERED_WEBM)
        os.remove(REGISTERED_WAV)
        if os.path.exists(REGISTER_FLAG):
            os.remove(REGISTER_FLAG)
        return jsonify({"result": "âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ã—ã£ã‹ã‚Šç™ºè©±ã—ã¦ãã ã•ã„ã€‚"})

    with open(REGISTER_FLAG, 'w') as f:
        f.write('registered')

    print("âœ… ç™»éŒ²å®Œäº†")
    return jsonify({"result": "âœ… å£°ã®ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼"})

@app.route('/is_registered', methods=['GET'])
def is_registered():
    registered = os.path.exists(REGISTER_FLAG)
    return jsonify({"registered": registered})

@app.route('/reset_registration', methods=['POST'])
def reset_registration():
    for file_path in [REGISTERED_WEBM, REGISTERED_WAV, REGISTER_FLAG]:
        if os.path.exists(file_path):
            os.remove(file_path)
    return jsonify({"reset": True})

@app.route('/verify_voice', methods=['POST'])
def verify_voice():
    print("ğŸ” è©±è€…åˆ¤å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡")

    if not os.path.exists(REGISTER_FLAG):
        print("âš ï¸ å£°ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€åˆ¤å®šä¸­æ­¢")
        return jsonify({"result": "âš ï¸ å£°ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã¯ã€Œå£°ã‚’ç™»éŒ²ğŸ¤ã€ãƒœã‚¿ãƒ³ã§ç™»éŒ²ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"})

    audio = request.files['audio_data']
    audio.save(VERIFY_WEBM)
    print("âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡ãƒ»ä¿å­˜å®Œäº†")

    try:
        webm_to_wav(VERIFY_WEBM, VERIFY_WAV)
        print("âœ… WebM â†’ WAV å¤‰æ›æˆåŠŸ")
    except Exception as e:
        print(f"âŒ WebM â†’ WAV å¤‰æ›å¤±æ•—: {e}")
        return jsonify({"result": "âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"})

    if is_silent(VERIFY_WAV):
        print("âš ï¸ éŸ³å£°ãŒç„¡éŸ³ã¨åˆ¤å®šã•ã‚ŒãŸãŸã‚ä¸­æ­¢")
        os.remove(VERIFY_WEBM)
        os.remove(VERIFY_WAV)
        return jsonify({"result": "âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ã—ã£ã‹ã‚Šç™ºè©±ã—ã¦ãã ã•ã„ã€‚"})

    if speaker_model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„")
        return jsonify({"result": "âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•ãŒå¿…è¦ã§ã™ã€‚"})

    print("ğŸ§  ãƒ¢ãƒ‡ãƒ«ã§ã‚¹ã‚³ã‚¢åˆ¤å®šé–‹å§‹")
    score, _ = speaker_model.verify_files(REGISTERED_WAV, VERIFY_WAV)
    print(f"âœ… ã‚¹ã‚³ã‚¢è¨ˆç®—å®Œäº†: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ = {score.item():.4f}")

    os.remove(VERIFY_WEBM)
    os.remove(VERIFY_WAV)

    SCORE_THRESHOLD = 0.65
    if score.item() >= SCORE_THRESHOLD:
        result = f"âœ… æœ¬äººã®å£°ã§ã™ã€‚(é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score.item():.2f})"
    else:
        result = f"âŒ æœ¬äººã®å£°ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚(é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score.item():.2f})"

    print(f"ğŸ¤ åˆ¤å®šçµæœ: {result}")
    return jsonify({"result": result})

if __name__ == "__main__":
    app.run()